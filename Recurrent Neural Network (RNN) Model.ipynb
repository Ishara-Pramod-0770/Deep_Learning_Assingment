{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a4a0f1-3205-4233-b4e0-5f17a256f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1ab3824-138f-41c6-9b1f-8077f39b89c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "heart_rate_non_linear_train = pd.read_csv('heart_rate_non_linear_features_train.csv')\n",
    "time_domain_train = pd.read_csv('time_domain_features_train.csv')\n",
    "frequency_domain_train = pd.read_csv('frequency_domain_features_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25d13be7-c9a9-4891-a255-0cbad512991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'datasetId' column in heart_rate_non_linear_train to string\n",
    "heart_rate_non_linear_train['datasetId'] = heart_rate_non_linear_train['datasetId'].astype(str)\n",
    "\n",
    "# First merge using 'datasetId' from heart_rate_non_linear_train and 'uuid' from time_domain_train\n",
    "train_data = pd.merge(heart_rate_non_linear_train, time_domain_train, left_on='datasetId', right_on='uuid', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f03aa22-41bf-4633-a096-b6ff4cbb05dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape after first merge: (0, 27)\n",
      "Columns in merged DataFrame after first merge: Index(['uuid_x', 'SD1', 'SD2', 'sampen', 'higuci', 'datasetId', 'condition',\n",
      "       'MEAN_RR', 'MEDIAN_RR', 'SDRR', 'RMSSD', 'SDSD', 'SDRR_RMSSD', 'HR',\n",
      "       'pNN25', 'pNN50', 'KURT', 'SKEW', 'MEAN_REL_RR', 'MEDIAN_REL_RR',\n",
      "       'SDRR_REL_RR', 'RMSSD_REL_RR', 'SDSD_REL_RR', 'SDRR_RMSSD_REL_RR',\n",
      "       'KURT_REL_RR', 'SKEW_REL_RR', 'uuid_y'],\n",
      "      dtype='object')\n",
      "Empty DataFrame\n",
      "Columns: [uuid_x, SD1, SD2, sampen, higuci, datasetId, condition, MEAN_RR, MEDIAN_RR, SDRR, RMSSD, SDSD, SDRR_RMSSD, HR, pNN25, pNN50, KURT, SKEW, MEAN_REL_RR, MEDIAN_REL_RR, SDRR_REL_RR, RMSSD_REL_RR, SDSD_REL_RR, SDRR_RMSSD_REL_RR, KURT_REL_RR, SKEW_REL_RR, uuid_y]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check merged DataFrame\n",
    "print(\"Merged DataFrame shape after first merge:\", train_data.shape)\n",
    "print(\"Columns in merged DataFrame after first merge:\", train_data.columns)\n",
    "print(train_data.head())  # Print first few rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ab34116-e15c-4679-8eb4-55e5b3bf5de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'uuid' column is missing in train_data. Check merge keys or column names.\n"
     ]
    }
   ],
   "source": [
    "# Now check if 'uuid' exists in the merged DataFrame\n",
    "if 'uuid' not in train_data.columns:\n",
    "    print(\"Error: 'uuid' column is missing in train_data. Check merge keys or column names.\")\n",
    "else:\n",
    "    # Now merge with the third dataset on 'uuid'\n",
    "    train_data = pd.merge(train_data, frequency_domain_train, on='uuid', how='inner')\n",
    "\n",
    "    # Check final merged DataFrame\n",
    "    print(\"Final merged DataFrame shape:\", train_data.shape)\n",
    "    print(\"Columns in final merged DataFrame:\", train_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22a1791a-46de-4f43-ac41-a4306b04419a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 0 entries\n",
      "Data columns (total 27 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   uuid_x             0 non-null      object \n",
      " 1   SD1                0 non-null      float64\n",
      " 2   SD2                0 non-null      float64\n",
      " 3   sampen             0 non-null      float64\n",
      " 4   higuci             0 non-null      float64\n",
      " 5   datasetId          0 non-null      object \n",
      " 6   condition          0 non-null      object \n",
      " 7   MEAN_RR            0 non-null      float64\n",
      " 8   MEDIAN_RR          0 non-null      float64\n",
      " 9   SDRR               0 non-null      float64\n",
      " 10  RMSSD              0 non-null      float64\n",
      " 11  SDSD               0 non-null      float64\n",
      " 12  SDRR_RMSSD         0 non-null      float64\n",
      " 13  HR                 0 non-null      float64\n",
      " 14  pNN25              0 non-null      float64\n",
      " 15  pNN50              0 non-null      float64\n",
      " 16  KURT               0 non-null      float64\n",
      " 17  SKEW               0 non-null      float64\n",
      " 18  MEAN_REL_RR        0 non-null      float64\n",
      " 19  MEDIAN_REL_RR      0 non-null      float64\n",
      " 20  SDRR_REL_RR        0 non-null      float64\n",
      " 21  RMSSD_REL_RR       0 non-null      float64\n",
      " 22  SDSD_REL_RR        0 non-null      float64\n",
      " 23  SDRR_RMSSD_REL_RR  0 non-null      float64\n",
      " 24  KURT_REL_RR        0 non-null      float64\n",
      " 25  SKEW_REL_RR        0 non-null      float64\n",
      " 26  uuid_y             0 non-null      object \n",
      "dtypes: float64(23), object(4)\n",
      "memory usage: 132.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# Explore data\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3df35e20-9621-48f5-81ec-8fef7e589825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [uuid_x, SD1, SD2, sampen, higuci, datasetId, condition, MEAN_RR, MEDIAN_RR, SDRR, RMSSD, SDSD, SDRR_RMSSD, HR, pNN25, pNN50, KURT, SKEW, MEAN_REL_RR, MEDIAN_REL_RR, SDRR_REL_RR, RMSSD_REL_RR, SDSD_REL_RR, SDRR_RMSSD_REL_RR, KURT_REL_RR, SKEW_REL_RR, uuid_y]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ee3caa7-db92-406b-ab23-f112c566d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Merge the dataframes if necessary to have a single DataFrame with all features\n",
    "train_data = pd.merge(heart_rate_non_linear_train, time_domain_train, on='uuid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29ec0d00-ec24-48fc-9aaa-4d699e92d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c7af4f6-fca0-4eaf-aa44-9012c185a70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns=['HR'])  # Assuming 'HR' is the target variable for heart rate\n",
    "y = train_data['HR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "626ef339-b589-4926-83b4-3a17b5d58a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify non-numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2cb3f61-ade8-4939-9bc8-b3cf3baba25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns: ['uuid', 'datasetId', 'condition']\n"
     ]
    }
   ],
   "source": [
    "non_numeric_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"Non-numeric columns:\", non_numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71133106-2770-4cdf-aead-78227ea6be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Drop non-numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d67553a0-6618-4a8d-a0a3-a899a6ac824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=non_numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f33f317a-9e66-4c19-bd17-3d8d63d079d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af139055-fac8-4681-8ef9-6a86a90684b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62565806-fd35-4f65-bddf-eb8834396ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c82843f-109f-47b9-8133-17e713bdee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46445c88-fd1e-4720-bf8d-996bc5a7d8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape for LSTM input [samples, timesteps, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a1b4536-852c-4a8c-97ba-22569658a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reshaped = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_val_reshaped = X_val.reshape((X_val.shape[0], 1, X_val.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83850d96-bd32-41c1-97bd-4982e5f24769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
